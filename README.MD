## 융복합 프로젝트 (AI, Big data, IoT, Cloud) _ 7조 _ ICU \_ 포트폴리오

---

#### 🖋SUMMARY

- 프로젝트 기간
  - 5월 23일 ~ 6월 28일

</br>

- 프로젝트 주제
  - 스토킹으로 인한 2차 범죄 예방을 위한 지능형 CCTV 개발

</br>

- 프로젝트 기획의도

  - 증가하는 스토킹
  - 피해자 보호 미흡
  - 단순 스토킹에서 흉악범죄로 이어지는 스토킹
  - CCTV의 범죄 예방 효과를 이용한 스토킹으로 인한 범죄 예방안 제시

</br>

- 프로젝트 목표
  - 지능형 CCTV 설치를 통한 개인 보안 강화 (실시간 영상 확인)
  - 스토킹 영상의 저장을 통한 증거 자료 수집 (영상 저장)
  - 이상행동 감지를 통한 스토킹 이후 2차 범죄를 예방 (이상행동 감지 및 알림)
  - 추후 효율적인 서비스 확대를 위한 지능형 CCTV의 우선입지 선정 조사

</br>

- 💬 지능형 cctv의 기능 구현 목표:

<B>💾 1. 증거자료 확보:</B> 사람의 이상행동을 감지하는 지능형 CCTV가 이상행동(스토킹과 비슷한 상황)을 스스로 감지하고 영상을 저장하여 범죄에 대한 증거자료를 확보함.

<B>📩 2. 실시간 영상 전송 및 알림:</B> 이상행동을 감지한 지능형 CCTV가 사용자의 휴대폰에 실시간으로 알림을 전달, 알림을 확인한 사용자는 실시간 영상 및 저장된 영상을 확인하여 상황을 파악함.

<B>☎ 3. 응급 전화 및 SMS 전송 기능:</B> 실시간 알림확인 후 상황을 파악한 사용자가 신속하게 위험상황에 대처가능함.

---

#### 👨‍👨‍👧‍👦 분야별 팀원 소개

- AI, Big data, IoT, Cloud 분야별 팀원 소개

#### 📖 프로젝트 구성도 소개

- 서비스 전체 구성도 및 상세 구성도

#### 📺 프로젝트 기능 소개 (시연영상, PPT)

- 서비스 전체 시연영상 및 PPT

#### 📚 회의록

- Notion 칸반 보드를 사용한 협업 및 주차별 수행일지
- 전체 WBS

#### 😀 느낀점

- 사진으로만 detecting을 하다가 비디오로 들어오는 객체를 detecting한 후 이상행동이라고 판단하기까지 정말 많은 논문과 책들을 찾아봤었습니다. YOLOv5, Mediapipe, Hands Estimation 정말 많은 관련된 자료들을 찾았고 보았고 공부했습니다. 이러한 모든 순간들이 제가 프로그램을 만드는 사람으로서 발전하는 순간이였다고 생각합니다. 

<br>

<B>💡 [자세한 정보 보러 가기](https://rustic-mailman-444.notion.site/7-f448609b0c2e4a69b5191be6b305f322) 💡</B>

<br>

---

## [인공지는(AI)]의 모델 선정이유 및 선정과정

---

### 프로젝트 환경

- Google Colab, Jupyter Note

---

### :memo: 인공지능(AI) 분야별 진행과정 및 트러블 슈팅

#### 1. 다양한 Media Detecting Model에 대한 조사
  - 5명의 인원이 각자 Video Detecting Model에 대한 조사를 시작하였고 OpenCV, Mediapipe pose estimation, Mediapipe hands estimation, Bodypix, YoLov5등 구글이나 다른곳에서 오픈소스로 제공되어지고 있는 모델등을 가지고 와서 우리 모델에 적용하는 방법을 채택함.
  
#### 2. 다양한 Detecting model에 대한 선정과정 및 사용할 모델 선정
  - Mediapipe pose estimation의 경우 사람의 몸에 포인트를 설정하고 그 포인트에 좌표를 설정하여 좌표의 움직을 통해서 신체를 추적하는 모델입니다. 
    - Mediapipe pose estimation을 사용하지 않은 이유 : 사람마다 키 패드나 손잡이를 잡는 모습이 모두 달라서 어떠한 모습이 이상행동이라고 정의하기 어렵기 때문에 사용하지 않았습니다.

![Mediapipe](https://user-images.githubusercontent.com/99243083/182310113-13c51627-fbc2-4d20-94e8-c8d289e3049d.jpeg)

---

  - Bodypix의 경우 사람과 배경을 분리해주는 모델입니다. 
    - Bodypix를 사용하지 않은 이유 : 화면이 밝기가 높았을때에는 사람과 배경을 분리 했으나 밝기가 어두워지면 사람과 배경을 구분하지 못하는 상황이 발생했습니다.
  
    ![Screenshot 2022-08-02 at 15 23 29](https://user-images.githubusercontent.com/99243083/182310709-17fd2d70-d86b-45fb-a58d-507eacd2436e.png)
    
    ---
  - Mediapipe hands estimation model의 경우 손의 움직임을 추적하여 위치에 손의 설정되어 있는 포인트를 좌표값으로 변환하여 손이 움직을 detect 해주는 모델입니다.
    - Mediapipe hands estimation model을 사용한 이유 : 이 모델의 경우 키 패드와 손잡이의 위치만 확실히 잡히게 되면 확실한 성능을 유지하였고, 손이 키 패드나 손잡이와 겹치게 되면 이상행동으로 판별하여 보다 쉽게 이상행동을 캐치할 수 있어서 선정하였습니다.
    - if 문으로 손이 키 패드나 손잡이에 겹치게 되면 이상행동으로 판별되어 1이 나오게 되면 mqtt 통신으로 신호를 보내게 되어있습니다. 
    
![hand_landmarks](https://user-images.githubusercontent.com/99243083/182845878-6099df3e-4ac8-4a92-a35c-dd8da2320afd.png)
---

- Yolov5의 경우의 경우 경계박스로 사물이나 사람을 detecting 하는 모델입니다.
  - Yolov5를 사용한 이유 :  꽤나 높은 수준의 성능과 실기간으로 판단이 가능해서 입니다. 
  - 사용된 모델 : 문 앞을 배회 하는 행동, 문에 귀를 대는 행동 판단, 키 패드나 손잡이에 손을 올리는 행동 이렇게 3가지 입니다.
    - 문 앞을 배회 하는 행동은 1분간 들어온 600장의 프레임 중 40%이상이면 이상행동으로 판단합니다.
    - 문에 귀를 대는 행동은 사람과 문이 겹치는 부분이 23%이상일때 이상행동으로 판답합니다. 
    - 키 패드나 손잡이에 손을 대는 행동은 (각 bounding box의 중심 간의 거리) < (각 bounding box의 반지름의 합) -> 이상행동으로 판단
  
   




